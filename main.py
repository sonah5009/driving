# Copyright (c) 2024 Sungkyunkwan University AutomationLab
#
# Authors:
# - Gyuhyeon Hwang <rbgus7080@g.skku.edu>, Hobin Oh <hobin0676@daum.net>, Minkwan Choi <arbong97@naver.com>, Hyeonjin Sim <nufxwms@naver.com>
# - url: https://micro.skku.ac.kr/micro/index.do

from pynq import Overlay, MMIO, PL, allocate
from pynq.lib.video import *
from pynq_dpu import DpuOverlay
import cv2
import numpy as np
import time
import os
import spidev
import keyboard
import matplotlib.pyplot as plt
from driving_system_controller import DrivingSystemController
from parking_system_controller import ParkingSystemController
from image_processor import ImageProcessor
from config import MOTOR_ADDRESSES, ULTRASONIC_ADDRESSES, ADDRESS_RANGE
from AutoLab_lib import init

# Jupyter í™˜ê²½ ê°ì§€
def is_jupyter_environment():
    """Jupyter í™˜ê²½ì¸ì§€ í™•ì¸"""
    try:
        shell = get_ipython().__class__.__name__
        if shell == 'ZMQInteractiveShell':  # Jupyter notebook
            return True
        elif shell == 'TerminalInteractiveShell':  # IPython terminal
            return False
        else:
            return False
    except NameError:
        return False

# matplotlib ì„¤ì • (Jupyter í™˜ê²½ì—ì„œë§Œ)
if is_jupyter_environment():
    plt.ion()  # ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ í™œì„±í™”
    print("Jupyter í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. matplotlibì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")

def draw_boxes_on_bev(bev_img, bev_boxes, color=(0, 255, 0)):
    """BEV ì˜ìƒ ìœ„ì— ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë¦¬ëŠ” í•¨ìˆ˜"""
    if bev_img is None:
        return None
    
    img = bev_img.copy()
    for box in bev_boxes:
        x1, y1, x2, y2 = int(box['x1']), int(box['y1']), int(box['x2']), int(box['y2'])
        class_name = box['class']
        score = box['score']
        
        # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
        
        # í´ë˜ìŠ¤ëª…ê³¼ ì ìˆ˜ í‘œì‹œ
        label = f"{class_name}: {score:.2f}"
        cv2.putText(img, label, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
    
    return img

def visualize_results(processed_info, frame_count=0):
    """ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜"""
    processed_image = processed_info['processed_image']
    bev_image = processed_info['bev_image']
    bev_boxes = processed_info['bev_boxes']
    lane_info = processed_info['lane_info']
    steering_angle = processed_info['steering_angle']
    calculated_speed = processed_info['speed']
    processing_time = processed_info['processing_time']
    
    if is_jupyter_environment():
        # Jupyter í™˜ê²½ì—ì„œ matplotlib ì‚¬ìš©
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'Autonomous Driving Visualization - Frame {frame_count}', fontsize=16)
        
        # 1. ì›ë³¸ ì²˜ë¦¬ëœ ì´ë¯¸ì§€
        #axes[0, 0].imshow(cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB))
        axes[0, 0].set_title(f'Processed Image\nSteering: {steering_angle:.1f}Â°, Speed: {calculated_speed:.1f} m/s')
        axes[0, 0].axis('off')
        
        # 2. BEV ì˜ìƒ (ë°”ìš´ë”© ë°•ìŠ¤ ì—†ìŒ)
        if bev_image is not None:
            #axes[0, 1].imshow(cv2.cvtColor(bev_image, cv2.COLOR_BGR2RGB))
            axes[0, 1].set_title('Bird\'s Eye View (Original)')
            axes[0, 1].axis('off')
        else:
            axes[0, 1].text(0.5, 0.5, 'No BEV Image', ha='center', va='center', transform=axes[0, 1].transAxes)
            axes[0, 1].set_title('Bird\'s Eye View (Not Available)')
            axes[0, 1].axis('off')
        
        # 3. BEV ì˜ìƒ + ë°”ìš´ë”© ë°•ìŠ¤
        if bev_image is not None and len(bev_boxes) > 0:
            bev_with_boxes = draw_boxes_on_bev(bev_image, bev_boxes)
            # axes[1, 0].imshow(cv2.cvtColor(bev_with_boxes, cv2.COLOR_BGR2RGB))
            axes[1, 0].set_title(f'BEV with Bounding Boxes\nDetected: {len(bev_boxes)} objects')
            axes[1, 0].axis('off')
        else:
            if bev_image is not None:
                #axes[1, 0].imshow(cv2.cvtColor(bev_image, cv2.COLOR_BGR2RGB))
                axes[1, 0].set_title('BEV with Bounding Boxes\nNo objects detected')
            else:
                axes[1, 0].text(0.5, 0.5, 'No BEV Image', ha='center', va='center', transform=axes[1, 0].transAxes)
                axes[1, 0].set_title('BEV with Bounding Boxes (Not Available)')
            axes[1, 0].axis('off')
        
        # 4. ì°¨ì„  ì •ë³´ ë° í†µê³„
        info_text = []
        info_text.append(f"Processing Time: {processing_time*1000:.1f} ms")
        info_text.append(f"Steering Angle: {steering_angle:.2f}Â°")
        info_text.append(f"Speed: {calculated_speed:.2f} m/s")
        
        if lane_info:
            info_text.append(f"Left Lane X: {lane_info.left_x:.1f}")
            info_text.append(f"Right Lane X: {lane_info.right_x:.1f}")
            info_text.append(f"Left Slope: {lane_info.left_slope:.3f}")
            info_text.append(f"Right Slope: {lane_info.right_slope:.3f}")
        
        info_text.append(f"Detected Objects: {len(bev_boxes)}")
        
        axes[1, 1].text(0.1, 0.9, '\n'.join(info_text), transform=axes[1, 1].transAxes, 
                       fontsize=10, verticalalignment='top', fontfamily='monospace')
        axes[1, 1].set_title('System Information')
        axes[1, 1].axis('off')
        
        plt.tight_layout()
        plt.pause(0.1)  # ì ì‹œ ëŒ€ê¸° (FPS ì¡°ì ˆ)
        
    else:
        # ì¼ë°˜ í™˜ê²½ì—ì„œ OpenCV ì‚¬ìš©
        # BEV ì˜ìƒì— ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        if bev_image is not None and len(bev_boxes) > 0:
            bev_with_boxes = draw_boxes_on_bev(bev_image, bev_boxes)
            cv2.imshow('BEV with Bounding Boxes', bev_with_boxes)
        
        # ê¸°ì¡´ ì²˜ë¦¬ëœ ì´ë¯¸ì§€ í‘œì‹œ
        cv2.imshow('Processed Image', processed_image)
        
        # ì •ë³´ í…ìŠ¤íŠ¸ ì¶”ê°€
        info_img = np.zeros((200, 400, 3), dtype=np.uint8)
        cv2.putText(info_img, f"Steering: {steering_angle:.1f}Â°", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(info_img, f"Speed: {calculated_speed:.1f} m/s", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        cv2.putText(info_img, f"Objects: {len(bev_boxes)}", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
        cv2.putText(info_img, f"Time: {processing_time*1000:.1f} ms", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
        cv2.imshow('System Info', info_img)

init()
# Initialize SPI
spi0 = spidev.SpiDev()
spi0.open(0, 0)
spi0.max_speed_hz = 20000000
spi0.mode = 0b00

# ììœ¨ì£¼í–‰ ëª¨ë“œ ë’·ë°”í€´ & ì¡°í–¥ ì†ë„ ì„¤ì • (0 ~ 100)
speed = 30  # 50ì—ì„œ 30ìœ¼ë¡œ ë‚®ì¶¤ (ë” ì•ˆì „í•œ ì†ë„)
steering_speed = 50
motors = {}

for name, addr in MOTOR_ADDRESSES.items():
    motors[name] = MMIO(addr, ADDRESS_RANGE)


def load_dpu():
    global dpu, input_data, output_data, shapeIn, shapeOut0, shapeOut1
    
    overlay = DpuOverlay("../dpu/dpu.bit")
    overlay.load_model("../xmodel/tiny-yolov3_coco_256.xmodel")
    
    dpu = overlay.runner
    
    return overlay, dpu

def main():
    overlay = load_dpu()
    controller = DrivingSystemController(overlay, dpu, motors, speed, steering_speed)
    
    # ì£¼ì°¨ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    ultrasonic_sensors = {}
    for name, addr in ULTRASONIC_ADDRESSES.items():
        ultrasonic_sensors[name] = MMIO(addr, ADDRESS_RANGE)
    
    parking_controller = ParkingSystemController(controller.motor_controller, ultrasonic_sensors)
    
    # ì‹œê°í™” ëª¨ë“œ ì„¤ì •
    show_visualization = True
    frame_count = 0
    
    # Jupyter í™˜ê²½ì—ì„œ matplotlib ì°½ ì„¤ì •
    if is_jupyter_environment() and show_visualization:
        plt.figure(figsize=(15, 10))
    
    try:
        # ê¸°ì¡´ run í•¨ìˆ˜ë¥¼ ìˆ˜ì •í•˜ì—¬ ì‹œê°í™” ì¶”ê°€
        video_path = None
        camera_index = 0
        
        # ì¹´ë©”ë¼ ë˜ëŠ” ë¹„ë””ì˜¤ ì´ˆê¸°í™”
        if video_path:
            cap = cv2.VideoCapture(video_path)
        else:
            cap = cv2.VideoCapture(camera_index)
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

        if not cap.isOpened():
            print("ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ì‹œì‘ ì‹œ ëª¨ë“œ ì„ íƒ
        print("\nì£¼í–‰ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
        print("1: ììœ¨ì£¼í–‰ ëª¨ë“œ")
        print("2: ìˆ˜ë™ì£¼í–‰ ëª¨ë“œ")
        print("P: ì£¼ì°¨ ì‹œìŠ¤í…œ ëª¨ë“œ")
        
        while True:
            if keyboard.is_pressed('1'):
                controller.switch_mode(1)
                break
            elif keyboard.is_pressed('2'):
                controller.switch_mode(2)
                break
            elif keyboard.is_pressed('p'):
                parking_controller.start_parking()
                break
            time.sleep(0.1)

        # ì œì–´ ì•ˆë‚´ ì¶œë ¥
        print("\ní‚¤ë³´ë“œ ì œì–´ ì•ˆë‚´:")
        print("Space: ì£¼í–‰ ì‹œì‘/ì •ì§€")
        print("1/2: ììœ¨ì£¼í–‰/ìˆ˜ë™ì£¼í–‰ ëª¨ë“œ ì „í™˜")
        print("P: ì£¼ì°¨ ì‹œìŠ¤í…œ ì‹œì‘/ì •ì§€")
        print("V: ì‹œê°í™” ì¼œê¸°/ë„ê¸°")
        if controller.control_mode == 2:
            print("\nìˆ˜ë™ ì£¼í–‰ ì œì–´:")
            print("W/S: ì „ì§„/í›„ì§„")
            print("A/D: ì¢ŒíšŒì „/ìš°íšŒì „")
            print("R: ê¸´ê¸‰ ì •ì§€")
        print("Q: í”„ë¡œê·¸ë¨ ì¢…ë£Œ\n")

        # ì„¼ì„œ ë°ì´í„° ì¶œë ¥ ì‹œê°„ ì œì–´ìš© ë³€ìˆ˜
        last_sensor_print_time = time.time()

        while True:
            # í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬
            if keyboard.is_pressed('space'):
                time.sleep(0.3)  # ë””ë°”ìš´ì‹±
                if parking_controller.is_parking_active:
                    print("ğŸš— ì£¼ì°¨ ì‹œìŠ¤í…œì´ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. P í‚¤ë¥¼ ëˆŒëŸ¬ ì£¼ì°¨ë¥¼ ì¤‘ì§€í•˜ì„¸ìš”.")
                elif controller.is_running:
                    controller.stop_driving()
                    print("ììœ¨ì£¼í–‰ ì¤‘ì§€ë¨")
                else:
                    controller.start_driving()
                    print("ììœ¨ì£¼í–‰ ì‹œì‘ë¨")
            
            elif keyboard.is_pressed('1') or keyboard.is_pressed('2'):
                if parking_controller.is_parking_active:
                    print("ì£¼ì°¨ ì‹œìŠ¤í…œì´ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. ì£¼ì°¨ë¥¼ ë¨¼ì € ì¤‘ì§€í•˜ì„¸ìš”.")
                else:
                    prev_mode = controller.control_mode
                    new_mode = 1 if keyboard.is_pressed('1') else 2
                    if prev_mode != new_mode:
                        controller.switch_mode(new_mode)
                        if new_mode == 2:
                            print("\nìˆ˜ë™ ì£¼í–‰ ì œì–´:")
                            print("W/S: ì „ì§„/í›„ì§„")
                            print("A/D: ì¢ŒíšŒì „/ìš°íšŒì „")
                            print("R: ê¸´ê¸‰ ì •ì§€")
                time.sleep(0.3)  # ë””ë°”ìš´ì‹±
            
            elif keyboard.is_pressed('p'):
                time.sleep(0.3)  # ë””ë°”ìš´ì‹±
                if controller.is_running:
                    print("ììœ¨ì£¼í–‰ì´ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. ì£¼í–‰ì„ ë¨¼ì € ì¤‘ì§€í•˜ì„¸ìš”.")
                elif parking_controller.is_parking_active:
                    parking_controller.stop_parking()
                    print("ì£¼ì°¨ ì‹œìŠ¤í…œ ì¤‘ì§€")
                else:
                    parking_controller.start_parking()
                    print("ì£¼ì°¨ ì‹œìŠ¤í…œ ì‹œì‘")
                    # ì£¼ì°¨ ì‹œìŠ¤í…œì´ ì‹œì‘ë˜ë©´ ìë™ìœ¼ë¡œ ì£¼ì°¨ ì‹¤í–‰ ì‹œì‘
                    print("ï¿½ï¿½ ì£¼ì°¨ ì‹¤í–‰ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            
            elif keyboard.is_pressed('v'):
                time.sleep(0.3)  # ë””ë°”ìš´ì‹±
                show_visualization = not show_visualization
                print(f"ì‹œê°í™”: {'ì¼œì§' if show_visualization else 'êº¼ì§'}")
            
            if keyboard.is_pressed('q'):
                print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

            # ì£¼ì°¨ ëª¨ë“œì—ì„œ ì´ˆìŒíŒŒ ì„¼ì„œ ë°ì´í„° ì§€ì†ì  ì¶œë ¥ (1ì´ˆë§ˆë‹¤)
            if parking_controller.is_parking_active:
                current_time = time.time()
                if current_time - last_sensor_print_time >= 1.0:  # 1ì´ˆë§ˆë‹¤ ì¶œë ¥
                    try:
                        # ì„¼ì„œ ë°ì´í„° ì§ì ‘ ì½ê¸°
                        sensor_distances = {}
                        for name, addr in ULTRASONIC_ADDRESSES.items():
                            try:
                                sensor = ultrasonic_sensors[name]
                                distance_raw = sensor.read(0x00, 4)  # 4ë°”ì´íŠ¸ ì½ê¸°
                                distance = int.from_bytes(distance_raw, byteorder='little') / 100.0  # cm ë‹¨ìœ„ë¡œ ë³€í™˜
                                sensor_distances[name] = max(0, min(500, distance))  # 0~500cm ë²”ìœ„ë¡œ ì œí•œ
                            except Exception as e:
                                sensor_distances[name] = 0.0
                                print(f"ì„¼ì„œ {name} ì½ê¸° ì˜¤ë¥˜: {e}")
                        
                        # ì„¼ì„œ ë°ì´í„° ì¶œë ¥ (ì£¼ì°¨ ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©í•˜ëŠ” ì„¼ì„œë“¤)
                        print(f"ğŸ” [ì´ˆìŒíŒŒ ì„¼ì„œ] ì „ë°©ìš°ì¸¡: {sensor_distances.get('ultrasonic_0', 0):.1f}cm, "
                              f"ì¤‘ê°„ìš°ì¸¡: {sensor_distances.get('ultrasonic_2', 0):.1f}cm, "
                              f"í›„ë°©ìš°ì¸¡: {sensor_distances.get('ultrasonic_4', 0):.1f}cm")
                        
                        last_sensor_print_time = current_time
                    except Exception as e:
                        print(f"ì„¼ì„œ ë°ì´í„° ì½ê¸° ì˜¤ë¥˜: {e}")

            # ì£¼ì°¨ ì‹œìŠ¤í…œ ì‹¤í–‰ (í™œì„±í™”ëœ ê²½ìš°)
            if parking_controller.is_parking_active:
                parking_controller.execute_parking_cycle()
                parking_status = parking_controller.get_status()
                print(f"ì£¼ì°¨ ìƒíƒœ: {parking_status['status_message']} (ë‹¨ê³„: {parking_status['phase']})")
                
                # ì£¼ì°¨ ì‹œìŠ¤í…œì´ í™œì„±í™”ëœ ê²½ìš° ììœ¨ì£¼í–‰ ì²˜ë¦¬ë¥¼ ê±´ë„ˆëœ€
                continue

            # í”„ë ˆì„ ì²˜ë¦¬ (ì£¼ì°¨ ì‹œìŠ¤í…œì´ ë¹„í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ)
            ret, frame = cap.read()
            if not ret:
                print("í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                break

            # ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ì°¨ëŸ‰ ì œì–´ (ì£¼ì°¨ ì‹œìŠ¤í…œì´ ë¹„í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ)
            processed_info = controller.process_and_control(frame)
            
            # ì‹œê°í™”
            if show_visualization:
                #visualize_results(processed_info, frame_count)
                frame_count += 1
                
                # Jupyter í™˜ê²½ì—ì„œëŠ” í”„ë ˆì„ ìˆ˜ë¡œ ì œì–´
                if is_jupyter_environment() and frame_count > 100:  # 100í”„ë ˆì„ í›„ ì¢…ë£Œ
                    break

    except KeyboardInterrupt:
        print("\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    finally:
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        cap.release()
        if is_jupyter_environment():
            plt.ioff()  # ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ ë¹„í™œì„±í™”
            plt.close('all')
        else:
            cv2.destroyAllWindows()
        controller.stop_driving()
        parking_controller.stop_parking()
        print("ëª¨ë“  ì‹œìŠ¤í…œì´ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()